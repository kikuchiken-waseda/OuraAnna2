# 2022_0117_MTG
小林先生とのミーティング. 
<br>1/17(月) 13:30-14:30. オンライン. 

## 先生memo
- 主成分分析で何を解析したのか
	- 正規化処理
- 正規化
	- 鼻や顔を使っては
- 正規化はできたとしましょう
- オプティカルフローの細かい矢印から、どう集約するか -> 集約することでわかりやすくなるのでは？
	- グループ化
	- クラスタリングでボトムアップにまとめる
	- 細かい矢印を表示した図をパターン化する①
	- 集約したベストな表現を設計する②
	- インストラクションに対応する運動変化をリストアップ
	- 中間状態で個々の運動の認識をして最終状態で結果を統合
	ex. 牛のお産
- 滑舌
	- 北村@甲南大
  
## my memo
### インターンシップの流れ
菊池先生：インターンシップの流れとしては以下の二つでは？
- 画像処理の基礎の構築. 
- 研究を随時進める. 

-> 後者の予定で進めていく. 

### 相談した内容
- 正規化:鼻や顔など, 剛体部分をより使っても良いかもしれない. 

ひとまず, 正規化はできたとして考えていこう. 
- 現状の結果では矢印がバラバラしていて分かりにくいから, なんとかして少数にまとめたい. 
  - クラスタリングやグループ化, パターン化などが考えられるけど, 今の段階ではやってもちょっと難しいのでは？理由は↓
- 現状のオプティカルフローはボトムアップ的な検出. ボトムアップも大切だけど, 近道ではない気がする. 
  - 「発話訓練にはこの運動を検出したいから〜」など何か前提があってそれを基に分析しているわけではなく, あくまでもRAWデータから検出をしたい, という流れで今までの研究は進んでいる. 
- トップダウン的なアプローチをすると, End-to-End などが使えるのでは. 
  - 例えば `入力:MRI -> ブラックボックス -> 出力:発話訓練のための指示` という構造で機械学習を組むとか. 
  - ここで課題になるのは **出力の条件** である. 今は聴覚障害者支援の視点から研究しているけど, 「聴覚障害者の発話支援ならどのような指示が必要なの？」を考える必要がある. 
  - その要件さえ決まれば, ブラックボックスに「補助的な情報(条件)」を組み込むことが可能になる. そうすると, 機械学習の精度も良くなる. 
- 聴覚障害者を対象とすると, どのタイミングで口を動かし音を出すのかという時間的構造の問題なども考慮し, 要件に加える必要がありそう. 
  - 聴覚障害者の調音運動に関する先行研究とかもあるのでは？
  - 聴覚障害者に最初から限定せずに, 一般人でも発話に苦手意識がある人とかも考慮してアプローチしていくと, 研究の幅が広げられて良いかもね. by小林先生
- 

### 課題
次のMTGまでには, 以下のことを考えてくる. 
- 誰をターゲットとする発話訓練システムを構築したいのか. 
- それに必要な要件・データとは何か. 

これらを決めた上で, どんなアプローチにすると良いかを考えて行く. 

そのために, 先行研究調査で以下のことを調べよう. 
- 聴覚障害者の調音運動を分析した研究. 
- (聴覚障害者に限らず)発話に苦手意識を持つ人の調音に関する研究. (北村先生@甲南大とか)

## 次の予定
2/9(水) 13:30-14:30
