# 0531_MTG

## やったこと
**4点による正規化**

4点での正規化をして、同じ舌尖の軌跡描画を行う。

背景
- 前回までの5点の正規化では（特に今回のように軌跡を見る場合には）問題がありそう。
- そこで、4点の情報を使って正規化をしてみる。

方法
- 発話者ごとに実行する。
- 発話者ごとの一番初めの画像の4点（歯茎、硬口蓋と軟口蓋の境界、第1脊椎、第3脊椎）の位置に、それ以降の画像の4点の位置を合わせる。
- 舌尖と思われる箇所をプロットする。
- 舌尖の位置情報を取得し、線でつなぐ。

データ
- /ra/ と言っているデータを対象に。10人の発話者（1人は2回撮影されているので11データ）。
- 舌が硬口蓋に接触する3フレーム前から。→ 黄色で軌跡を描画
- 舌が硬口蓋に接触した瞬間から、離れて安定するまで（ここもう少し統制した方が良かったかも）。→ 水色で軌跡を描画

結果
||good|bad|
|---|---|---|
|正規化前|<img src="https://user-images.githubusercontent.com/61837100/165221752-c26f42b4-3aa7-4fc1-95d3-c6be7da16d8d.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221766-84ac8478-069b-4785-8301-0556af5d20c4.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221773-76ad164a-3f43-4518-9839-b5a48749342e.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221779-e2291d60-0061-4e53-b07f-e8c7d7d9e176.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221787-d768da15-0e03-489e-aac6-b03a6f3d740e.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221798-c147f4fa-9927-4283-9238-5a038eeb79b0.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221807-78184722-33f5-4388-8a8e-76114c9d5298.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221816-96ecb86a-3c4a-4b7f-8146-5c53e33a274e.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221822-9fe9063d-0917-4454-b368-e6a6114516a0.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/165221832-c0f2a04f-ddef-4af5-9e16-716841d5b73a.png" width="130">|<img src="https://user-images.githubusercontent.com/61837100/165221845-f85313eb-a534-4bbe-b22f-fc28e1d0152a.png" width="200">|
|前回の正規化|<img src="https://user-images.githubusercontent.com/61837100/168529326-959d6140-4ce5-4344-a05c-952d7f9bb094.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168529271-2c5b6990-cb29-452c-ad63-7f0ec801c7dc.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168529362-b7eb9c3a-26d0-4265-bb93-335be96e536f.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168529372-c340e4f6-4462-476a-acca-e27bc72c74cc.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168529394-e0e6262e-d826-444f-8c10-094b3ebf1a32.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168529423-4057f2f5-c772-4073-b38f-f8001e118bdf.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168505466-69addedb-6fb9-476c-aebc-450699ce9fa6.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168505482-41dc16bf-5581-449d-8523-3e8cc817032c.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168505523-bb5a6c37-5a31-4661-b3c4-d424b0e489fd.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/168505542-0c9ea26a-9870-428e-a4eb-2be28174a571.png" width="130">|<img src="https://user-images.githubusercontent.com/61837100/168505777-9dcede3a-d3a7-4ba5-8183-4606b96c912e.png" width="200">|
|今回|<img src="https://user-images.githubusercontent.com/61837100/170872371-f9764c37-1d05-4df2-9106-39c0a9d46f00.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872376-41be6457-3865-43b9-8afa-ceb8dbfc9ffd.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872382-e7866dbf-53c3-415a-b37b-80e23153ab67.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872389-4bd9e5d1-eb29-4d0c-9632-b77f0a70ba67.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872394-7e78e5a2-9116-4ab7-9ae3-2e44d31aeddd.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872399-71631bf8-8e13-41ae-9da6-57863f2845c1.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872420-6907b62b-b732-4c18-8a93-88a7eeb128a3.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872427-998e99b6-c0d8-4493-8df5-634bb712ce09.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872433-ed5084cd-406b-4aca-aeff-7e784087e551.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170872439-86ae4bae-22be-41d7-970c-e179553898aa.png" width="130">|<img src="https://user-images.githubusercontent.com/61837100/170872447-600080a8-57d8-4936-a352-91a04eba2d8a.png" width="200">|

考察
- 正規化前とあまり変わらない＝個人内の首の動きはあまり大きくない。
- 一枚一枚見たところ、前回の正規化のような「頭が動き過ぎている」という現象は見られない。
- ただ、この方法では個人内はOKだが個人間の正規化はできない。
- 個人間の正規化はむしろ、前回の5角形の正規化を使えば良いのでは？下顎も含めることで、「剛体部分の正規化」ではなくて「声道形状も考慮した正規化」ができる？

**データの確認**

もっと/ra/発話時の画像があるかもしれない。太字が今扱っているデータ。
- 2019_0111 のが見当たらない・・・？

```
/var/www/rmdjs/data/20170714/Fujimoto/WEBM/luminance_numbered/7.webm
/var/www/rmdjs/data/20170714/Kikuchi/WEBM/luminance_numbered/7.webm
**/var/www/rmdjs/data/20171110/Maekawa/WEBM/luminance_numbered/7.webm**
**/var/www/rmdjs/data/20171110/Masaki/WEBM/luminance_numbered/7.webm**
/var/www/rmdjs/data/20171110/Nota/WEBM/luminance_numbered/7.webm
**/var/www/rmdjs/data/20171225/Kagomiya/WEBM/luminance_numbered/7.webm**
**/var/www/rmdjs/data/20171225/Saito/WEBM/luminance_numbered/8.webm**
**/var/www/rmdjs/data/20171225/Asai/WEBM/luminance_numbered/7.webm**
**/var/www/rmdjs/data/20180305/Morimoto/WEBM/luminance_numbered/8.webm**
**/var/www/rmdjs/data/20180305/Koiso/WEBM/luminance_numbered/7.webm**
/var/www/rmdjs/data/20180720/Kato/WEBM/luminance_numbered/8.webm
/var/www/rmdjs/data/20180720/Enomoto/WEBM/luminance_numbered/8.webm
**/var/www/rmdjs/data/20180808/Honda/WEBM/luminance_numbered/7.webm**
/var/www/rmdjs/data/20190208/Sukegawa/WEBM/luminance_numbered/7.webm
/var/www/rmdjs/data/20190208/Matsuda/WEBM/luminance_numbered/9.webm
/var/www/rmdjs/data/20190527/Mori/WEBM/luminance_numbered/7.webm
/var/www/rmdjs/data/20190527/Okahisa/WEBM/luminance_numbered/7.webm
/var/www/rmdjs/data/20191210/Kagomiya/WEBM/luminance_numbered/21.webm
/var/www/rmdjs/data/20191210/Kagomiya/WEBM/luminance_numbered/22.webm
/var/www/rmdjs/data/20191210/Kagomiya/WEBM/luminance_numbered/23.webm
/var/www/rmdjs/data/20191210/Kikuchi/WEBM/luminance_numbered/21.webm
/var/www/rmdjs/data/20191210/Kikuchi/WEBM/luminance_numbered/22.webm
/var/www/rmdjs/data/20191210/Kikuchi/WEBM/luminance_numbered/23.webm
/var/www/rmdjs/data/20191210/Saito/WEBM/luminance_numbered/21.webm
/var/www/rmdjs/data/20191210/Saito/WEBM/luminance_numbered/22.webm
/var/www/rmdjs/data/20191210/Masaki/WEBM/luminance_numbered/20.webm
/var/www/rmdjs/data/20191210/Masaki/WEBM/luminance_numbered/21.webm
/var/www/rmdjs/data/20200213/Fujimaki/WEBM/luminance_numbered/13.webm
/var/www/rmdjs/data/20200213/Fujimaki/WEBM/luminance_numbered/14.webm
/var/www/rmdjs/data/20200303/Nota/WEBM/luminance_numbered/24.webm
/var/www/rmdjs/data/20200303/Nota/WEBM/luminance_numbered/25.webm
/var/www/rmdjs/data/20200303/Kato/WEBM/luminance_numbered/24.webm
/var/www/rmdjs/data/20200303/Kato/WEBM/luminance_numbered/25.webm
/var/www/rmdjs/data/20200303/Kato/WEBM/luminance_numbered/26.webm
/var/www/rmdjs/data/20200303/Matsuda/WEBM/luminance_numbered/24.webm
/var/www/rmdjs/data/20200303/Matsuda/WEBM/luminance_numbered/25.webm
/var/www/rmdjs/data/20200303/Matsuda/WEBM/luminance_numbered/26.webm
/var/www/rmdjs/data/20200303/Matsuda/WEBM/luminance_numbered/29.webm
/var/www/rmdjs/data/20200303/Matsuda/WEBM/luminance_numbered/30.webm
/var/www/rmdjs/data/20200303/Matsuda/WEBM/luminance_numbered/31.webm
/var/www/rmdjs/data/20200722/Maekawa/WEBM/luminance_numbered/31.webm
/var/www/rmdjs/data/20200722/Maekawa/WEBM/luminance_numbered/32.webm
/var/www/rmdjs/data/20200821/Asai/WEBM/luminance_numbered/34.webm
/var/www/rmdjs/data/20200821/Asai/WEBM/luminance_numbered/35.webm
/var/www/rmdjs/data/20200821/Asai/WEBM/luminance_numbered/36.webm
/var/www/rmdjs/data/20200821/Asai/WEBM/luminance_numbered/37.webm
/var/www/rmdjs/data/20200910/Honda/WEBM/luminance_numbered/26.webm
/var/www/rmdjs/data/20200910/Honda/WEBM/luminance_numbered/27.webm
/var/www/rmdjs/data/20201001/Takemoto/WEBM/luminance_numbered/11.webm
/var/www/rmdjs/data/20201120/Hirai/WEBM/luminance_numbered/8.webm
/var/www/rmdjs/data/20201120/Hirai/WEBM/luminance_numbered/9.webm
/var/www/rmdjs/data/20210409/Yamada/WEBM/luminance_numbered/18.webm
/var/www/rmdjs/data/20211019/Yamamoto/WEBM/luminance_numbered/10.webm
/var/www/rmdjs/data/20211207/Yamashita/WEBM/luminance_numbered/10.webm
```

**補足：オプティカルフローの実行**

4点の正規化をしたうえで、卒論で報告したオプティカルフローを実行した。

方法
- 正規化
  - 上に同じ。
- オプティカルフロー
  - 正規化処理済みの 256×256 px の画像を対象に行う。
  - 1フレーム目と2フレーム目を比較する。
  - 検出したフローのうち、1px以上の大きさを持つフローを採択する。
  - 採択したフローを、2フレーム目に8pxごとに矢印で表示する。
  - 最後のフレームまで同様の処理を繰り返す。
- バイラテラル
  - バイラテラルフィルタの原理。
  - 正規化処理済みの 256×256 px の画像を対象に行う。
  - フィルタの強さは・・・で、・・回繰り返し処理を行う。
  - 上の処理を施した画像を、上と同じオプティカルフロー処理にかける。
- 空間方向の主成分分析の利用
  - 特にどこが周囲と異なった運動を行っているかを検証するため、主成分分析を用いる。
  - 正規化処理済み&バイラテラルフィルタ済みの 256×256 px の画像を対象に行う。
  - 1フレーム目と2フレーム目を比較する。
  - 8px ごとで 3×3 のボクセルを設定する。
  - ボクセル内にある矢印の縦軸・横軸それぞれの成分を対象に主成分分析を行い、ボクセル中央のピクセルの寄与率を算出する。
  - ボクセル中央のピクセルのフローの縦軸・横軸それぞれの長さに、寄与率で重みづけを行う。
  - 検出したフローのうち、3px以上の大きさを持つフローを採択する。
  - 採択したフローを、2フレーム目に8pxごとに矢印で表示する。
  - 最後のフレームまで同様の処理を繰り返す。

データ
- 上に同じ。
- ここでは、舌をリリースしたタイミングの画像を載せる。

結果
||good|bad|
|---|---|---|
|image|<img src="https://user-images.githubusercontent.com/61837100/170957935-04676bdd-82c6-4ba5-ae44-3957928a959c.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170957975-ad31bae2-34ee-4099-8e2e-de51b70cf03b.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170958003-01941b97-acec-4e31-9bae-98e84a693289.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170958043-ef26fddf-fa04-4013-ae22-fe60830e160c.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170958132-b9dbf40c-dcf3-4970-bdd3-06808138224f.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170958298-3509673f-5c22-4a1b-a088-5de26e9bf4e3.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170958325-b6ecff6b-caf6-44b3-9824-e6814f7a6578.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170958345-ec8b1de4-6fb3-4a20-9a62-8c1a6627fdd4.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170958388-032a061f-5785-4e27-ae72-aa20afcea158.png" width="130"><img src="https://user-images.githubusercontent.com/61837100/170959382-5edeedc5-2676-4f07-870f-9b0993c46448.png" width="130">|<img src="https://user-images.githubusercontent.com/61837100/170958548-288d0873-a95d-433e-b9d7-74ed507e7d21.png" width="200">|

考察
- 舌のリリース方向に関して、意外と見れていそう。
- 輪郭情報も応用してみると面白いかもしれない。

## 議事録
- アフィンじゃなくて、回転・拡大縮小だけの方が良いかもしれない。
- goodとbadの明確な違いが見れるか？と思ったけど、そうでもなさそう。
  - データ数を増やせばなんとかなるかもしれないし、なんとかならないかもしれない。とりあえずデータほかにないか見てみよう。
  - あと、goodとbadの判断はのノイズ除去していないもので行った。そこで、桂田先生のやっているノイズ除去の資料をもう一度見てみると良いのでは。
  - 先生：Dropbox上にデータが見つからない場合、僕が前川さんに聞くのでもいいです。
- オプティカルフローで、離れる瞬間だけを見るのはちょっと厳しいかも。複数枚の連続した流れで観察しよう。
- 4点で個人間も正規化できるのでは？
  - 本来は、生データから違いを確認する→違いそうな箇所を見つける→個人間正規化して比較、というつもりだった。しかし、今はその「違いそうな箇所」が見当たりにくい。
  - そこで、個人間の正規化はまだ早いかもしれない。
  - もちろん、大浦がやりたいのであればやって良いと思う。
- 同じ状況での /da/ も観たい。
  - rtMRI全体の発話データを見てみよう。撮影時に提示される発話内容データとか、どっかにあるのでは。
  - 科研ミーティングでのスライドでOK、とりあえずどの音がどのデータに保存されているのかを見たい。

メインテーマに関して
- VAEを使えば良い感じに推定できるのでは。
- そのためには、MRIのデータ数どれだけあるかは確認する必要ある。
- 菊池先生：https://ruor.uottawa.ca/handle/10393/41533

## 課題
- /ra/ の他データがないか探す。
- /da/ と言っているデータがないかも探す。→ 発話内容を示した資料ある？
- 桂田先生の、ノイズ除去済みの音声データないか探す。→ goodは本当にgoodか？
- その他、もろもろ進める。

次回：6/22 13:30
