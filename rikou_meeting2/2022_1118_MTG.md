# 2022_1118_MTG

## 現状の進捗
推定MRIをひとまず出力できた。

### データ
- 任意の一人の話者（`speaker__id = 1`）のMRI。
- 全て 27 fps の動画。
  - 210 data × 513 frame = 107,730 frame ?
- 無声区間も含んだ動画全体。
- 元の MRI は 256×256 px。舌付近の 100×100 px を、68×68 px の大きさで読み込む。
  - 容量が大きくて 100 × 100 px だと動かないので、なるべく解像度を下げないような工夫をした。

### 結果
画像全体 vs トリミング後
- 学習構造は BiLSTM-CNN 。とりあえず動かせることを目的に。この学習構造にした明確な理由はない。
- 以下は同じ音声を入力した際の推定結果。全体の推定だとほとんど舌が動いていないが、トリミング後は動いている。

|全体|トリミング後|
|---|---|
|<img src="https://user-images.githubusercontent.com/61837100/202199167-b6ccfdb3-3180-4245-a104-92222b9da2a7.gif" width="200">|<img src="https://user-images.githubusercontent.com/61837100/202198914-1a011099-3779-4cd5-a82a-dd42e0b95944.gif" width="200">|

手法ごとの比較
- 従来手法(海外の方の研究？)も含めて、4手法試してみた。
- 理科大の方の研究によると、基の MRI との差は FC-DNN < LSTM < BiLSTM-CNN < BiLSTM とのこと。
  - 評価基準：MSE, SSIM
  - 本研究では正確な数値の算出はしていないが、肉眼だと概ね同じ傾向か？
  - 疑問点：舌単体で見た時では、評価値も異なるはず。

|FC-DNN|LSTM|BiLSTM|BiLSTM-CNN|
|---|---|---|---|
|<img src="https://user-images.githubusercontent.com/61837100/202201221-6bec5136-b934-4016-8abc-d3fe88b3cc1c.gif" width="200">|<img src="https://user-images.githubusercontent.com/61837100/202201071-c99d5793-e4c9-45a5-b5fe-58a3f546c41b.gif" width="200">|<img src="https://user-images.githubusercontent.com/61837100/202201237-53f53b2d-6e2f-470a-b573-c83722375c4e.gif" width="200">|<img src="https://user-images.githubusercontent.com/61837100/202198914-1a011099-3779-4cd5-a82a-dd42e0b95944.gif" width="200">|

## 今後の課題
- 研究目標の再確認。
  - 何を推定すべきか。
  - 母音のみ？
- 舌単体での評価値はどうか。
- 有声区間のみにしてみてはどうか。
- 他の被験者、かつ他の fps の動画も一気に学習できないか。

***
## フィードバック
